{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_prep import preprocess_data\n",
    "df = pd.read_csv('datasets/melbourne_house_price.csv', index_col=0)\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Price_above_median']\n",
    "x = df.drop(['Price_above_median'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "rs = 0\n",
    "xtr, xtst, ytr, ytst = train_test_split(x.values, y, test_size=0.3, stratify=y, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation and Logistic Regresison\n",
    "#### a) What is the difference between logistic and linear regression?\n",
    "Logistic regression aims to locate a class based outcome. It uses the sigmoid function normally with log-loss to attempt to minimize the cost of the function and find the most optimal weights? It makes use of a piecewise function to determine the class of each item, normally <0.5 is one class and >0.5 is the other.\n",
    "Linear regression has an output that is continous. It creates a linear line that maps the expected output. Performs poorly for probabilities as they can be negative.\n",
    "#### b) Describe how logisitic regressions...?\n",
    "#### c) Perform standardisation on the training and test data set. What is it?\n",
    "Standardisation is the act of transforming data so it has a mean of 0 and a std deviation of 1.\n",
    "#### d) What does standardisation do to the data. How does it benefit the regression model?\n",
    "As above. It benefits models that are sensitive to outliers by scaling them down so that the models won't apply too much weight to these violating datums.\n",
    "#### e) Why fit standardisation model to the training data instead of both the training and test?\n",
    "This is likely because the scaling to the test data is pointless when training a model because this data is unseen and would result in the training data not scaling properly -> the model observing badly scaled items as more/less important.\n",
    "#### f) Fit a logistic regression model to your training data. How does it perform on the training and test data? Overfitting?\n",
    "Strong evidence of overfitting as the training set performs significantly better than the test set.\n",
    "#### g) Use GridSearchCV to tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rickm\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "xtr = scaler.fit_transform(xtr, ytr)\n",
    "xtst = scaler.transform(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:  0.894656037791556\n",
      "Test set accuracy:  0.8787711806033889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=rs)\n",
    "model.fit(xtr, ytr)\n",
    "print('Training set accuracy: ', model.score(xtr, ytr))\n",
    "print('Test set accuracy: ', model.score(xtst, ytst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [pow(10,x) for x in range(-6,4)]}\n",
    "cv=GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs),cv=10,n_jobs=1)\n",
    "cv.fit(xtr, ytr)\n",
    "\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(xtr, ytr))\n",
    "print(\"Test accuracy:\", cv.score(xtst, ytst))\n",
    "\n",
    "y_pred = cv.predict(xtst)\n",
    "print(classification_report(ytst, y_pred))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = \n",
    "features_names = \n",
    "indices = np.argsort(importances)\n",
    "indices = np.flip(indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
